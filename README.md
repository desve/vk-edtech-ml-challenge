# VK EdTech ML Challenge: прогноз эффективности рекламных кампаний

Репозиторий с end‑to‑end решением задачи VK EdTech ML Challenge: по истории показов рекламы и профилям пользователей предсказать эффективность будущих рекламных кампаний.  
Цель — оценить вероятность того, что хотя бы один / два / три пользователя из аудитории совершат целевое действие.

Локальная метрика качества (официальный `metrics.py`, Smoothed Mean Log Accuracy Ratio, меньше — лучше): **37.51%** на валидации.

---

## Данные

Используются четыре табличных файла в формате TSV (разделитель — табуляция):

- `users.tsv` — пользователи:
  - `user_id`, `sex`, `age`, `city_id`.
- `history.tsv` — история показов:
  - `hour`, `cpm`, `publisher`, `user_id`.
- `validate.tsv` — описание кампаний для валидации:
  - `cpm`, `hour_start`, `hour_end`, `publishers`, `audience_size`, `user_ids`.
- `validate_answers.tsv` — ответы для валидации:
  - `at_least_one`, `at_least_two`, `at_least_three`.

Файлы данных **не хранятся в репозитории**. Их нужно скачать с официальной страницы задачи VK EdTech ML Challenge и положить локально, например так:
```
data/raw/
users.tsv
history.tsv
validate.tsv
validate_answers.tsv
```

В ноутбуках путь к данным задаётся переменной `FOLDER` (в Colab используется `/content/drive/MyDrive/VK_Project_v2`).

---

## Фичи

Для каждой кампании из `validate` строится вектор признаков (одна строка на кампанию):

- Демография аудитории:
  - средний пол и возраст (`sex_mean`, `age_mean`);
  - количество уникальных городов (`city_nunique`);
  - кластер кампании по (sex_mean, age_mean) через `KMeans(n_clusters=5)`.
- История показов в окне `[hour_start, hour_end]` по пользователям кампании:
  - доля пользователей, попавших в историю (`in_history_frac`);
  - среднее число показов на пользователя (`n_shows_mean`);
  - среднее число уникальных паблишеров на пользователя (`n_unique_pub_mean`);
  - средний и медианный CPM по пользователям (`mean_cpm_mean`, `median_cpm_mean`);
  - 10‑й и 90‑й перцентили CPM (`quantile_cpm_10`, `quantile_cpm_90`).
- Rolling‑статистики CPM по часам:
  - для каждого часа считаются `roll_cpm_mean`, `roll_cpm_median`, `roll_cpm_std` по окну ±24 часа;
  - для кампании берётся медиана этих значений по её часовому окну.
- Параметры кампании:
  - размер аудитории (`audience_size`);
  - длительность окна в часах (`window_hours`);
  - плановый CPM (`cpm`);
  - число паблишеров (`n_publishers`).

Результат: `features_df` с размерностью `1008 × N` (восстановленная версия из исходного решения VK).

---

## Модели

Основная идея — двухступенчатая модель: классификатор, который отсекает кампании с почти нулевым откликом, и ансамбль регрессоров для оставшихся.

### Классификатор

- Целевой класс `y_class` формируется по трём таргетам (`at_least_one`, `at_least_two`, `at_least_three`) с порогами:
  - класс 0: все таргеты < 0.01;
  - класс 1: все таргеты < 0.05;
  - класс 2: остальные кампании.
- Модель:
  - `RandomForestClassifier(
      n_estimators=400,
      max_depth=16,
      min_samples_leaf=2,
      class_weight={0: 3.0, 1: 2.0, 2: 1.0},
      random_state=42
    )`.

### Стек‑регрессии + калибровка

Для каждого таргета (`at_least_one`, `at_least_two`, `at_least_three`) обучается стек‑регрессор на логарифмах таргета:

- базовые модели:
  - `LGBMRegressor(n_estimators=150, num_leaves=32, learning_rate=0.05, random_state=42)`;
  - `HistGradientBoostingRegressor(max_iter=200, max_depth=8, random_state=42)`;
  - `RidgeCV(alphas=[0.01, 0.1, 1, 10])`;
- мета‑модель:
  - `RidgeCV(alphas=[0.1, 1, 10])`;
- калибровка:
  - `IsotonicRegression(out_of_bounds='clip')` по лог‑предсказаниям.

Финальное предсказание по кампании:

- если класс 0 → `[0.0, 0.0, 0.0]`;
- если класс 1 → фиксированный шаблон `[0.02, 0.01, 0.005]`;
- если класс 2 → выход стек‑регрессий + калибровка, затем обратное лог‑преобразование и отсечение отрицательных/слишком малых значений.

---

## Метрика

Оценка проводится официальным скриптом `metrics.py` из условия конкурса.

- Метрика: **Smoothed Mean Log Accuracy Ratio**, формула из условия задачи.  
- Интерпретация: средняя относительная ошибка в процентах, **чем меньше — тем лучше**.  
- Текущий результат на валидации (`validate_answers.tsv` + `submission.tsv` из этого репозитория):  
  - `SMLogAccRatio ≈ 37.51%`.

В ноутбуке `04_submission_and_report.ipynb` автоматически:

- формируется `submission.tsv` (3 столбца, 1008 строк, без индекса);  
- запускается `metrics.py`;  
- генерируется текстовый AutoReport с датой запуска, параметрами модели и значением метрики.

---

## Как запустить

### Вариант: Google Colab + Google Drive

1. Склонировать репозиторий или открыть ноутбук напрямую из GitHub:

   - открыть в браузере нужный ноутбук, например  
     `https://github.com/desve/vk-edtech-ml-challenge/blob/main/notebooks/03_modeling.ipynb`;
   - заменить в адресе `github.com` на `colab.research.google.com/github/...` и открыть ссылку.

2. В Colab смонтировать Google Drive и указать путь к данным:



